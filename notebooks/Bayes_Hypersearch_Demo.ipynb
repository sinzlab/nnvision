{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo Notebook for Bayesian Hyperparameter Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datajoint as dj\n",
    "\n",
    "dj.config[\"enable_python_native_blobs\"] = True\n",
    "dj.config['nnfabrik.schema_name'] = \"nnfabrik_hypersearch_demo\"\n",
    "schema = dj.schema(\"nnfabrik_hypersearch_demo\")\n",
    "\n",
    "import nnfabrik\n",
    "import torch\n",
    "from nnfabrik.main import *\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import datajoint as dj\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import pickle \n",
    "\n",
    "import nnfabrik\n",
    "from nnfabrik import main, builder\n",
    "\n",
    "import nnvision\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the Bayesian Class from nnfabrik\n",
    "from nnfabrik.utility.hypersearch import Bayesian\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Dataset, Trainer, and Model, the parameters that should be optimized should be defined in the _auto dictionarys\n",
    "# Here are example usages for all the entries.\n",
    "# Those parameters should not be defined in the respective configs\n",
    "\n",
    "model_config_auto = dict(\n",
    "\n",
    "    gamma_readout={\"type\": \"range\", \"bounds\": [1e-6, 1e-1], \"log_scale\": True},\n",
    "    init_noise={\"type\": \"range\", \"bounds\": [1e-6, 1e-1], \"log_scale\": True},   \n",
    ")\n",
    "dataset_config_auto = dict(\n",
    "    batch_size={\"type\": \"choice\", \"values\": [50, 64]}\n",
    ")\n",
    "\n",
    "trainer_config_auto = dict(\n",
    "    lr_init={\"type\": \"range\", \"bounds\": [0.001, 0.005], \"log_scale\": True},\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Fabrikant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # change this entry to reflect your datajoint username\n",
    "Fabrikant().insert1(dict(fabrikant_name='kwilleke',\n",
    "                          email=\"konstantin.willeke@gmail.com\",\n",
    "                          affiliation='sinzlab',\n",
    "                          dj_username=\"kwilleke\"))\n",
    "Seed().insert1(dict(seed=1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "basepath = '/data/monkey/toliaslab/CSRF19_V1'\n",
    "neuronal_data_path = os.path.join(basepath, 'neuronal_data/')\n",
    "neuronal_data_files = [neuronal_data_path+f for f in listdir(neuronal_data_path) if isfile(join(neuronal_data_path, f))]\n",
    "image_file = os.path.join(basepath, 'images/CSRF19_V1_images.pickle')\n",
    "image_cache_path = os.path.join(basepath, 'images/individual')\n",
    "\n",
    "\n",
    "dataset_fn = 'nnvision.datasets.monkey_static_loader'\n",
    "dataset_config = dict(dataset='CSRF19_V1',\n",
    "                               neuronal_data_files=neuronal_data_files[:15],\n",
    "                               image_cache_path=image_cache_path,\n",
    "                               crop=80,\n",
    "                               subsample=1,\n",
    "                               seed=1000,\n",
    "                               time_bins_sum=12,\n",
    "                               batch_size=128,)\n",
    "dataset_config_auto = dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fn = 'nnvision.models.se_core_spatialXfeature_readout'\n",
    "model_config =  {'pad_input': False,\n",
    "   'stack': -1,\n",
    "   'depth_separable': True,\n",
    "   'input_kern': 24,\n",
    "   'gamma_input': 20,\n",
    "   'hidden_dilation': 1,\n",
    "   'hidden_kern': 7,\n",
    "   'hidden_channels': 32}\n",
    "\n",
    "model_config_auto = dict(\n",
    "\n",
    "    gamma_readout={\"type\": \"range\", \"bounds\": [1e-6, 1e-1], \"log_scale\": True},\n",
    "    init_noise={\"type\": \"range\", \"bounds\": [1e-6, 1e-1], \"log_scale\": True},   \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add the Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_fn = 'nnvision.training.nnvision_trainer'\n",
    "trainer_config = dict(max_iter=100,\n",
    "                      verbose=False, \n",
    "                      lr_decay_steps=4,\n",
    "                      avg_loss=False, \n",
    "                      patience=5,\n",
    "                      lr_init=.0045)\n",
    "trainer_config_auto = dict(\n",
    "              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run Bayesian Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting the bayesian Search:\n",
    "# The number of total trials can be varied, but 200 trials is usually sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autobayes = Bayesian(dataset_fn, dataset_config, dataset_config_auto,\n",
    "              model_fn, model_config, model_config_auto,\n",
    "              trainer_fn, trainer_config, trainer_config_auto, architect=\"kwilleke\", trained_model_table='nnfabrik.my_trained_model.TrainedModel', total_trials=200)\n",
    "\n",
    "best_parameters, _, _, _ = autobayes.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}